# GAN-tionary 

<br>

## Data Visualizations via Question Answering (DVQA)

---
<br>

**Synthesis Reports:**

**CNNs** ~ https://adityapanwar.notion.site/Convolutional-Neural-Networks-CNNs-efe2763d947840139181791481c33591

**RNNs**  ~ https://adityapanwar.notion.site/Recurrent-Neural-Networks-RNNs-c1dc36bbf163451a87bd27663e77df9d

**LSTMs** ~ https://adityapanwar.notion.site/Long-Short-Term-Memory-Networks-LSTMs-1bdf250766744ec995d8b917a09e2f62

**Attentions** ~ https://adityapanwar.notion.site/Attention-Models-2ab02fd42a77415da1a590b5658612d1

**Transformers** ~ https://www.notion.so/adityapanwar/Transformers-21736229e7a34ef2ab22dd1dd1064696

**GANs** ~ https://www.notion.so/adityapanwar/Generative-Adversarial-Networks-GANs-e3269251e2a2415aad6af29bd479cfa0

**Kaggle Notebook for GANs** ~ <https://www.kaggle.com/code/samyabose/gans-for-generating-weakly-reflexive-relations?kernelSessionId=97919755>

---
<br>


**Datasets:**

**DVQA** ~ <https://drive.google.com/drive/folders/1EzduOrm1izxP2DlqZs89OD7vYIjZULgm?usp=sharing**>

**VQA Abstract** ~ <https://drive.google.com/drive/folders/1vIbuQACWagN0j3qoeSuDUdVKUMvBHCwv?usp=sharing>

[Containing model weights, preprocessed data, performance measure etc.]

---
<br>

**Notebooks:**

**SAN-VQA Demonstration** ~ <https://colab.research.google.com/drive/1gLexF10EtafVxWEYHHp8Lv53H2WEDC_R?usp=sharing>

**SAN-VQA on VQA** ~ <https://colab.research.google.com/drive/12MYBlhD2hUPK0GZ8FjmIqGvleph_jf1U?usp=sharing>

**Preprocessing of DVQA** ~ <https://colab.research.google.com/drive/1G_TmUqKx3bXukhUQKn8KK948jm5JcGPO?usp=sharing>

**SAN-VQA on DVQA** ~ <https://colab.research.google.com/drive/1DMTx0lkz2UvyBEFyO2mBn5veEppvY_rf?usp=sharing>

**Binary Classifier** ~ <https://colab.research.google.com/drive/1C2tyshkPEgaPdLW_9V5IyQ2shi1TRrGV?usp=sharing>

**Regression Model and OCR** ~ <https://colab.research.google.com/drive/1dtjMx0FjDGG8FV5XyGNwKFPwkWRFkuUq?usp=sharing>

**Performance Analysis of PReFIL** ~
<https://colab.research.google.com/drive/13bcnxXMIBO2ne69uJwhseFhDkIv1uxtD?usp=sharing>


<br>
<br>

## pix2pix

---
<br>

**Datasets:**

**Link for all datasets -** <http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/>

**Drive link for all things necessary for pix2pix -** <https://drive.google.com/drive/folders/1mm3zxxlA_KwEdM3UbYDpAbQLwnEkBQsA?usp=sharing>

---
<br>


**Notebooks:**

**Demonstration of pix2pix -** <https://colab.research.google.com/drive/1HBbk8KdCNuZpOeNNKe-HDspD51Rvd3hK?usp=sharing>

**Detailed Study on pix2ix -** <https://colab.research.google.com/drive/1i1juRFut85oLUYAlC3E0-k1XKQn6M31N?usp=sharing>
